{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ac4ffd-2f35-4fa2-9740-cda9be8e034b",
   "metadata": {},
   "source": [
    "# Predict Employee Burnout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07f43b-2221-46e8-a4d5-2f13f7e9add9",
   "metadata": {},
   "source": [
    "## 1. Business Problem and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b7d45-90b4-4f5d-b8dd-248111f93e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, \\\n",
    "GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from xgboost import XGBRegressor\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967b7d7-9a30-4b6c-9afe-f89e0fe5ff97",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30245a57-64e1-4a56-b439-3d6b0c3c5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "sample_submission = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7178c13-67ed-44fd-b237-328d0d8ae06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train & test\n",
    "\n",
    "full_df = pd.concat([train,test],axis=0)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feaaae2-7479-4e55-a976-1e4190768675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform column names\n",
    "\n",
    "full_df.columns = full_df.columns.str.lower()\n",
    "full_df.columns = full_df.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3b5a1-222c-46d1-940b-ecde23659ad3",
   "metadata": {},
   "source": [
    "It looks like we have some missing values in the last 3 columns of the data set. With so much missing from the `burn_rate` we cannot drop those values, we would ideally impute on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d628a-7d05-4cc5-9729-6031e8b7e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd472a1e-97bf-43d6-832b-11bfbf015b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isna().sum()/full_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cf3e3-1d90-43a8-a563-4f721c49edba",
   "metadata": {},
   "source": [
    "We can see that all numeri columns are a scale, `burn_rate`, our target is from 0-1. We may want to adjust that to be on a 1-10 scale as the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c366b7-4bcf-4913-b425-66e9b6d9c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f329d-c8bc-440c-8823-e5141e0b4b74",
   "metadata": {},
   "source": [
    "## 3. Data Exporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ef106-02af-46fe-a603-878ad67282b5",
   "metadata": {},
   "source": [
    "It looks like all of the columns with missingness are mostly normally distributed, so we can confidently impute with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf133a-4609-428e-b529-d4e4b15fb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_df['burn_rate']);\n",
    "\n",
    "print('mean:',np.nanmean(full_df['burn_rate']))\n",
    "print('median:',np.nanmedian(full_df['burn_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97cd2f0-2a0f-4e96-bc19-ca6c2cd23904",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_df['mental_fatigue_score']);\n",
    "\n",
    "print('mean:',np.nanmean(full_df['mental_fatigue_score']))\n",
    "print('median:',np.nanmedian(full_df['mental_fatigue_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f331a4f-2d23-4792-8087-9155c55f7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_df['resource_allocation']);\n",
    "\n",
    "print('mean:',np.nanmean(full_df['resource_allocation']))\n",
    "print('median:',np.nanmedian(full_df['resource_allocation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934bbab7-659d-4cd8-927b-48caf08d893b",
   "metadata": {},
   "source": [
    "We also don't have any duplicates so we can drop `employee_id` along with `date_of_joining` since we are working with one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eebf7c-e8bc-48c3-a7f7-db441fe6feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.duplicated(subset=['employee_id']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc8a97-3fef-4959-8c50-d861dc5ef1d8",
   "metadata": {},
   "source": [
    "### Target Variable `burn_rate`\n",
    "\n",
    "Since we want to conduct a predictive model and better understand which employees are at risk of burnout, we will create a label column defining burnout. Since the metric was on a 0-1 scale, for ease of interpretation, we will increase this scale by 10 and round the number to the nearest whole number.\n",
    "\n",
    "It looks like we have a slight class imbalance which we should try to address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9b970-33d6-43dd-bfbf-dee4545299fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['burn_label'] = full_df['burn_rate'].apply(lambda x: round(x*10) if not np.isnan(x) else x)\n",
    "full_df['burn_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc2587-8407-4956-87fe-a6615164a24b",
   "metadata": {},
   "source": [
    "Unfortunately we have to drop the missing values in our target in order to split our data into train/test. This will reduce our dataset quite a bit but hopefully we can get decent results still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea83ec-01df-4df3-9a61-7a9ef22c2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total size after dropping target nas:',full_df.shape[0])\n",
    "print('Total missing values of target:',full_df['burn_label'].isna().sum())\n",
    "\n",
    "y_nas_dropped = full_df.dropna(subset=['burn_label'])\n",
    "\n",
    "print('Total size after dropping target nas:',y_nas_dropped.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4528e01-0ba5-46b8-89ea-8df8063243dd",
   "metadata": {},
   "source": [
    "## 4. Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f91b03-10e6-46ec-996a-3bcb22cf8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X, y and split train/test\n",
    "\n",
    "X = y_nas_dropped.drop(columns=['date_of_joining','employee_id','burn_label','burn_rate'])\n",
    "y = y_nas_dropped['burn_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, stratify=y)\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb49b4-566e-485f-9a36-fdc8687d0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define num and cat subpipes\n",
    "subpipe_num = Pipeline(steps=[('num_impute', SimpleImputer()),\n",
    "                           ('ss', StandardScaler())])\n",
    "subpipe_cat = Pipeline(steps=[('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))])\n",
    "\n",
    "# Create column transformer\n",
    "CT = ColumnTransformer(transformers=[('subpipe_num', subpipe_num, [3, 4, 5]),\n",
    "                                         ('subpipe_cat', subpipe_cat, [0, 1, 2])],\n",
    "                           remainder='passthrough')\n",
    "# Initial pipeline\n",
    "lr_pipe = Pipeline(steps=[('ct', CT),\n",
    "                            ('model', LinearRegression())])\n",
    "                            \n",
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05208c-0ec0-4233-b875-825c580e89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline score\n",
    "\n",
    "print('Train Score:', root_mean_squared_error(y_train,lr_pipe.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a3cc4-3ada-4192-ab16-dd1554ac6955",
   "metadata": {},
   "source": [
    "## 5. Linear Regression Model\n",
    "\n",
    "First, lets see if we can improve our LinearRegression model with testing out our Lasso and Ridge models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73bdfc-f69b-4121-81bc-683c43bdf41a",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae77ae7-1fb7-4d0d-af15-2d66f5af5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in pipeline\n",
    "\n",
    "lasso_pipe = lr_pipe.set_params(model=Lasso())\n",
    "lasso_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822121e-1657-49c9-b357-2e55ca87ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameter grid\n",
    "params = {\n",
    "    'model__alpha':[.0001,.001,.01,1,10,100,1000],\n",
    "    'model__selection': ['cyclic','random']\n",
    "    \n",
    "}\n",
    "\n",
    "rcv=RandomizedSearchCV(lasso_pipe,param_distributions=params,scoring='neg_root_mean_squared_error',\n",
    "                 return_train_score=True,cv=5,random_state=42,n_iter=15)\n",
    "\n",
    "rcv.fit(X_train,y_train)\n",
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b032e-d526-4279-b867-87132092ffb1",
   "metadata": {},
   "source": [
    "We actually did worse after cross validation. It looks like our model isn't over/under fitting so that's a bonus. We may want to try a different type of model next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c04ad3-e7ed-4f78-80ab-1fb6f8e7eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quick function to see the scores easier for future models\n",
    "def rcv_metrics(rcv,model_name,X,y,train_df=None):\n",
    "    best_estimator = rcv.best_estimator_\n",
    "    score_dict = {'Val Train Score': -np.mean(rcv.cv_results_['mean_train_score']),\n",
    "                 'Val Test Score':-np.mean(rcv.cv_results_['mean_test_score']),\n",
    "                 'Model Name': model_name}\n",
    "    score_df = pd.DataFrame(score_dict,columns=['Model Name','Val Train Score',\n",
    "                                                'Val Test Score'], index=range(1))\n",
    "    if train_df is None:\n",
    "        pass\n",
    "    else:\n",
    "       score_df = pd.concat([train_df,score_df])\n",
    "       score_df.index = range(len(score_df))\n",
    "    return score_df, best_estimator\n",
    "    \n",
    "train_scores, lasso_best = rcv_metrics(rcv,'Lasso',X_train,y_train)\n",
    "train_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1318d-f7e1-4070-8821-a25c5bb2b6e1",
   "metadata": {},
   "source": [
    "Our score on our test is around the same as on our train, so we know there is no overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d913cf-fc13-462e-a983-5cf130b76a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dislay f1 score and confusion matrix\n",
    "def test_metrics(model,model_name,X,y,test_df=None):\n",
    "    score_dict = {'Model Name':model_name,\n",
    "                  'Train Score': root_mean_squared_error(y_train,model.predict(X_train)),\n",
    "                  'Test Score': root_mean_squared_error(y, model.predict(X))}\n",
    "    score_df=pd.DataFrame(score_dict,columns=['Model Name','Train Score','Test Score'],index=range(1))\n",
    "    if test_df is None:\n",
    "        pass\n",
    "    else:\n",
    "       score_df = pd.concat([test_df,score_df])\n",
    "       score_df.index = range(len(score_df))\n",
    "       score_df.sort_values(by='Test Score')\n",
    "    return score_df\n",
    "    \n",
    "\n",
    "# Predict on the test\n",
    "test_scores = test_metrics(lasso_best,'Lasso',X_test,y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e70f58-2d29-472b-b3fa-67127bc29b07",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "\n",
    "Now we can assess the Ridge model in comparison to Lasso to see which type of regularization is best for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1c7f6-2ed7-4164-b892-3f1aa382c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in pipeline\n",
    "\n",
    "ridge_pipe = lr_pipe.set_params(model=Ridge())\n",
    "ridge_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bd3f6-ae08-462e-802c-7a1ee2870609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameter grid\n",
    "params = {\n",
    "    'model__alpha':[.0001,.001,.01,1,10,100,1000],\n",
    "    'model__solver': ['auto','svd','cholesky','lsqr','sag'],\n",
    "    'model__tol': [1e-5,1e-3,1e-2,1e-1]\n",
    "    \n",
    "    \n",
    "}\n",
    "rcv=RandomizedSearchCV(ridge_pipe,param_distributions=params,scoring='neg_root_mean_squared_error',\n",
    "                 return_train_score=True,cv=5,random_state=42,n_iter=15)\n",
    "\n",
    "rcv.fit(X_train,y_train)\n",
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea317465-5181-4df7-a220-f99a6065679b",
   "metadata": {},
   "source": [
    "Our Ridge model did so much better than the Lasso on the validation scores and around the same on our test, It is definitely the stronger of the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08603fdb-4298-494a-b8f0-1b0769a41225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, ridge_best = rcv_metrics(rcv,'Ridge',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(ridge_best,'Ridge',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948231e-dc90-4409-829c-54297f9511f2",
   "metadata": {},
   "source": [
    "### `SMOTE` for Class Imbalance\n",
    "\n",
    "Since we know we have a class imbalance, lets see how our model does if we incorporate `SMOTE` and balance out our target class, making sure to only resample all classes but the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40b69c-37e7-45bb-ae50-3c87bc9177ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new pipe with `SMOTE` and the a logisitic model with best parameters found with RandomizedCV\n",
    "\n",
    "imb_pipe = ImPipeline(steps=[('ct',CT),\n",
    "                            ('sm',SMOTE(random_state=42,sampling_strategy='not majority')),\n",
    "                            ('model', Ridge())])\n",
    "\n",
    "# Define new parameter grid\n",
    "params = {\n",
    "    'model__alpha':[.0001,.001,.01,1,10,100,1000],\n",
    "    'model__solver': ['auto','svd','cholesky','lsqr','sag'],\n",
    "    'model__tol': [1e-5,1e-3,1e-2,1e-1]\n",
    "    \n",
    "    \n",
    "}\n",
    "rcv=RandomizedSearchCV(imb_pipe,param_distributions=params,scoring='neg_root_mean_squared_error',\n",
    "                 return_train_score=True,cv=5,random_state=42,n_iter=15)\n",
    "\n",
    "rcv.fit(X_train,y_train)\n",
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6786ec-8162-4986-a4b6-34b9352f24dc",
   "metadata": {},
   "source": [
    "Looks like `SMOTE` increased our scores substantially! We will leave smote out of the pipeline going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198368a2-6ea8-43af-8ac3-818d4d165536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, ridge_sm = rcv_metrics(rcv,'Ridge Sm',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(ridge_sm,'Ridge Sm',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eca69e-ec02-4b25-a125-9cf6ab7c8f23",
   "metadata": {},
   "source": [
    "## 6. DecisionTree Regressors\n",
    "\n",
    "Let's see if Decision Tree regressors can improve our scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275d610-fd49-4abb-b491-8b25ef8c2057",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Next we will try a simple Decision Tree to see if the bagging and subspace sampling can get us a more stable score between model and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d8ce4-3937-4231-b70b-91f616f090fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in pipeline\n",
    "\n",
    "dec_pipe = ridge_pipe.set_params(model=DecisionTreeRegressor(random_state=42))\n",
    "dec_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bafde-660b-4e6b-8776-44cb6e49ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params = {'model__criterion': ['squared_error', 'absolute_error','poisson'],\n",
    "          'model__max_depth': [None, 10, 20, 30, 40],\n",
    "          'model__min_samples_split': [2, 5, 10, 20],\n",
    "          'model__splitter': ['best', 'random'],\n",
    "          'model__min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "rcv = RandomizedSearchCV(dec_pipe,param_distributions=params,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=15)\n",
    "\n",
    "rcv.fit(X_train,y_train)\n",
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c4de4-5ec7-4eaa-8953-3643e5e02642",
   "metadata": {},
   "source": [
    "Looks like our Decision Tree did better than our Ridge but it is underfitting a bit, so hopefully the Random Forest and help address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36349a8-aa02-41f8-8f77-244cb8ea043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, dec_best = rcv_metrics(rcv,'Decision',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(dec_best,'Decision',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab631e1-2044-4770-b461-74f895034220",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Since Random Forests are better at addressing over/under fitting, we will try to see if we can improve our model with this ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6867bad-f849-4f74-80f3-5bc5de3a441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Regressor in pipeline\n",
    "\n",
    "forest_pipe = ridge_pipe.set_params(model=RandomForestRegressor(random_state=42))\n",
    "forest_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac448a-b871-4ab2-b6c8-a007a36cfd26",
   "metadata": {},
   "source": [
    "It takes quite a bit to go through all the options available for some of these ensemble models so we will add a verbose of 3 for these to make sure that the code is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726fd2d-c6fe-4d42-9c88-d4631c634511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params = {'model__criterion': ['squared_error', 'poisson'],\n",
    "          'model__max_depth': [None, 10, 20, 30, 40],\n",
    "          'model__min_samples_split': [2, 5, 10, 20],\n",
    "          'model__warm_start': [True,False],\n",
    "          'model__min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "rcv = RandomizedSearchCV(forest_pipe,param_distributions=params,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=15,verbose=3)\n",
    "\n",
    "rcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e86a19-d5ce-4b64-a25c-3725b0553542",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76d4e4-4cd5-432e-97db-39a1ea976443",
   "metadata": {},
   "source": [
    "The Random Forest did even better than our Decision Tree on the validation data and test daya. However, it is still underfitting a bit. Lastly we will try some boosting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a8b8a-3304-433b-b388-16b10b3e5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, forest_best = rcv_metrics(rcv,'Forest',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(forest_best,'Forest',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca709-4986-4122-800c-7faa67d039c7",
   "metadata": {},
   "source": [
    "## 7. Boosting Regressors\n",
    "\n",
    "Lets see boosting Regressors yeild better results, starting with `GradientRegressor` first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03bc2-4bdd-4126-a0a2-b9ed36f6f322",
   "metadata": {},
   "source": [
    "### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939f325-7fc8-4f09-bed9-adc48a131cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in pipeline\n",
    "\n",
    "gradient_pipe = ridge_pipe.set_params(model=GradientBoostingRegressor(random_state=42))\n",
    "gradient_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdb98b-ea1a-47f0-997a-7c0f2eab4998",
   "metadata": {},
   "source": [
    "We will set verbose to 3 so that we can confirm the code is running as this CV takes a bit for the boosting algorithms to run when there are this many hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089250c3-7f89-44eb-a2fa-3da70711bf98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params_gb = {'model__max_depth': [3, 5, 10, None],\n",
    "          'model__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "          'model__n_estimators': [50, 100, 200, 300, 400],\n",
    "          'model__min_samples_split':  [2, 5, 10, 20],\n",
    "          'model__max_features': ['sqrt','log2',None],\n",
    "          'model__subsample': [0.5, 0.75, 1.0],\n",
    "          'model__min_samples_leaf': [1, 2, 5, 10]\n",
    "          \n",
    "}\n",
    "\n",
    "rcv_gb = RandomizedSearchCV(gradient_pipe,param_distributions=params_gb,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=18,verbose=3)\n",
    "\n",
    "rcv_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048434c-5277-46ce-9687-e1a45ec899eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters of best estimate\n",
    "rcv_gb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945df1d-5885-4c0c-aae9-54f6a91f538c",
   "metadata": {},
   "source": [
    "Our Gradient Boost is underfitting on the validation data but not so much on the train/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8952ebf-e29b-423b-bb44-0a080a4cbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, gradient_best = rcv_metrics(rcv_gb,'GradientBoost',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(gradient_best,'GradientBoost',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89f3bc-c32f-436f-882f-56550a9fa8e5",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27ad96-a18c-4268-8cd8-cd10b304d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Regressor in pipeline\n",
    "\n",
    "xgboost_pipe = ridge_pipe.set_params(model=XGBRegressor(random_state=42))\n",
    "xgboost_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c3c31-5d4a-4095-b0ff-428567daa563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params_xgb = {'model__learning_rate':  [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "          'model__n_estimators': [50, 100, 200, 300, 400],\n",
    "          'model__min_child_weight':  [3, 5, 7, 9, 11],\n",
    "          'model__colsample_bytree': [0.5, 0.75, 1.0],\n",
    "          'model__subsample': [0.5, 0.75, 1.0],\n",
    "          'model__reg_alpha':  [0, 0.1, 0.5, 1.0],\n",
    "          'model__reg_lambda':  [0, 0.1, 0.5, 1.0],\n",
    "          'model__max_depth': [3, 5, 7, 9, 11]\n",
    "}\n",
    "\n",
    "rcv_xgb = RandomizedSearchCV(xgboost_pipe,param_distributions=params_xgb,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=12,verbose=3)\n",
    "\n",
    "rcv_xgb.fit(X_train,y_train)\n",
    "rcv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9cea0-f1d1-40cf-8615-6761a5e25273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters of the best estimator\n",
    "rcv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2121da7-8a25-4bdc-b137-66627eb0a1ae",
   "metadata": {},
   "source": [
    "Very similar results as our Gradient Boost, our validation scores are slightly higher so this model might have a bit more variance. This model is also underfitting slighly more on our train/test data, with test scores nearly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc38fa-b2b5-44ec-a597-0f4c6f97fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, xgb_best = rcv_metrics(rcv_xgb,'XGBoost',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(xgb_best,'XGBoost',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9bb10-a8ff-4229-8b37-225932095a3f",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "The last boosting model we'll try is AdaBoost with our XGBoost as our base estimator since it had the best score with the least underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a33d7-997e-4c49-a8c9-b7dc6fb2e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Regressor in pipeline\n",
    "\n",
    "ada_pipe = ridge_pipe.set_params(model=AdaBoostRegressor(random_state=42,estimator=xgb_best['model']))\n",
    "ada_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4017f4-080a-44a2-ac76-63a6c976266d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params_ada = {'model__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "          'model__n_estimators': [50, 100, 200, 300, 400],\n",
    "          'model__loss': ['linear','square']\n",
    "}\n",
    "\n",
    "rcv_ada = RandomizedSearchCV(ada_pipe,param_distributions=params_ada,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=3,verbose=3)\n",
    "\n",
    "rcv_ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96916473-6ee4-465b-ad58-05e8be094ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcv_ada.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b790d-28ad-43cf-ad01-74679b892594",
   "metadata": {},
   "source": [
    "Adaboost is doing slightly better than XGBoost, but not by much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f1d3f-d46c-413d-92a2-ac90c7c63406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, ada_best = rcv_metrics(rcv_ada,'AdaBoost',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(ada_best,'AdaBoost',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1066e-9e8a-4070-a01b-99900d5adfdb",
   "metadata": {},
   "source": [
    "## 8. Averaging & Weighted Avereging\n",
    "\n",
    "Lastly, we will take some of our best models and create combined models to see if we can get the best out of all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaea31-a8ba-4efb-b259-ee18027ba2b2",
   "metadata": {},
   "source": [
    "### VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f3fd2-c6f1-434c-b66c-ae940ad7ea0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create weighted averaging \n",
    "\n",
    "estimators = [\n",
    "    ('ridge',ridge_best),\n",
    "    ('xgb',xgb_best),\n",
    "    ('ada',ada_best)\n",
    "]\n",
    "\n",
    "voting_pipe = ridge_pipe.set_params(model=VotingRegressor(estimators=estimators, weights=[.2,.4,.4]))\n",
    "\n",
    "voting_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1029653-2a06-431c-b717-a1e619fab61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params_voting = {'model__voting': ['hard','soft']\n",
    "}\n",
    "\n",
    "rcv_voting = RandomizedSearchCV(voting_pipe,param_distributions=params_w_avg,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=2,verbose=3)\n",
    "\n",
    "rcv_voting.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96685a5a-670f-48e7-8d4b-da948490ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters of the beast estimator\n",
    "rcv_voting.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776215b-2b64-4825-aaca-51a613961a00",
   "metadata": {},
   "source": [
    "Our Voting Regressor did slightly worse than our GradientBoost and XGBoost and is overfitting slightly more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf021d39-bdeb-44d4-8531-ad5854f47a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, voting_best = rcv_metrics(rcv_voting,'Voting',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(voting_best,'Voting',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c88f1-12fb-41f0-8dc6-0b3c6f115393",
   "metadata": {},
   "source": [
    "### StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c1ecd-acb4-42fc-b8ce-c746c10e6e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace in pipe\n",
    "\n",
    "estimators = [\n",
    "    ('ridge',ridge_best),\n",
    "    ('gb',gradient_best),\n",
    "    ('xgb',xgboost_best)\n",
    "]\n",
    "\n",
    "stacking_pipe = ridge_pipe.set_params(model=StackingRegressor(estimators=estimators))\n",
    "\n",
    "stacking_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4e420-c77a-47ef-9637-96950a630c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomizedsearch CV \n",
    "\n",
    "params_stacking = {'model__stack_method': ['auto', 'predict_proba', 'decision_function', 'predict'],\n",
    "                   'model__final_estimator': [xgb_best['model'],ada_best['model']]\n",
    "}\n",
    "\n",
    "rcv_stacking = RandomizedSearchCV(stacking_pipe,param_distributions=params_stacking,scoring='neg_root_mean_squared_error',\n",
    "                        return_train_score=True,random_state=42,n_iter=2,verbose=3)\n",
    "\n",
    "rcv_stacking.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896e49a-882e-4c38-a093-327597b89365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters of the beast estimator\n",
    "rcv_stacking.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2133a8e-0409-4ced-bbd3-49dc554c55c4",
   "metadata": {},
   "source": [
    "Looks like Stacking gives us around the same results as Voting! It is also overfitting on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e636c-666d-40be-b247-706abd4827dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test metrics\n",
    "train_scores, stacking_best = rcv_metrics(rcv_stacking,'Stacking',X_train,y_train,train_scores)\n",
    "display(train_scores)\n",
    "\n",
    "test_scores = test_metrics(stacking_best,'Stacking',X_test,y_test,test_scores)\n",
    "display(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038edbbd-4bf5-4801-a06e-8564149db042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env-lite-2)",
   "language": "python",
   "name": "learn-env-lite-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
